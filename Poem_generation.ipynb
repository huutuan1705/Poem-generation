{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-08-08T14:57:32.795744Z","iopub.status.busy":"2024-08-08T14:57:32.795376Z","iopub.status.idle":"2024-08-08T14:57:46.744330Z","shell.execute_reply":"2024-08-08T14:57:46.743377Z","shell.execute_reply.started":"2024-08-08T14:57:32.795714Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting gdown\n","  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n","Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.2)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.13.1)\n","Requirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.32.3)\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.66.4)\n","Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2024.7.4)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\n","Downloading gdown-5.2.0-py3-none-any.whl (18 kB)\n","Installing collected packages: gdown\n","Successfully installed gdown-5.2.0\n"]}],"source":["!pip install gdown"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T14:57:59.136810Z","iopub.status.busy":"2024-08-08T14:57:59.136237Z","iopub.status.idle":"2024-08-08T14:58:04.556274Z","shell.execute_reply":"2024-08-08T14:58:04.555153Z","shell.execute_reply.started":"2024-08-08T14:57:59.136677Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n","  warnings.warn(\n","Downloading...\n","From: https://drive.google.com/uc?id=1GAOHCLC5-7PlWy1kHPXq2r36xgrmu92W\n","To: /kaggle/working/poem_dataset.csv\n","100%|██████████████████████████████████████| 51.6k/51.6k [00:00<00:00, 70.2MB/s]\n"]}],"source":["!gdown --id 1GAOHCLC5-7PlWy1kHPXq2r36xgrmu92W"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T14:58:04.559250Z","iopub.status.busy":"2024-08-08T14:58:04.558795Z","iopub.status.idle":"2024-08-08T14:58:17.738728Z","shell.execute_reply":"2024-08-08T14:58:17.737874Z","shell.execute_reply.started":"2024-08-08T14:58:04.559209Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-08-08 14:58:06.616936: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-08-08 14:58:06.617053: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-08-08 14:58:06.749061: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]}],"source":["import os\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import re\n","import random\n","\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from nltk.translate.bleu_score import sentence_bleu, corpus_bleu\n","\n","RANDOM_SEED = 1\n","tf.random.set_seed(RANDOM_SEED)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T14:58:20.017690Z","iopub.status.busy":"2024-08-08T14:58:20.016327Z","iopub.status.idle":"2024-08-08T14:58:20.024326Z","shell.execute_reply":"2024-08-08T14:58:20.023267Z","shell.execute_reply.started":"2024-08-08T14:58:20.017657Z"},"trusted":true},"outputs":[],"source":["# Prepare data\n","def text_normalize(text):\n","    text = text.lower()\n","    text = text.strip() \n","    text = re.sub(r'[^\\w\\s\\n]', '', text)\n","    text = text.replace('\\n\\n', '\\n')\n","    text = '\\n'.join(['<start> ' + line + ' <end>' for line in text.split('\\n') if line != '' and len(line.split()) == 5])\n"," \n","    return text"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T14:58:22.351139Z","iopub.status.busy":"2024-08-08T14:58:22.350466Z","iopub.status.idle":"2024-08-08T14:58:22.354972Z","shell.execute_reply":"2024-08-08T14:58:22.354142Z","shell.execute_reply.started":"2024-08-08T14:58:22.351096Z"},"trusted":true},"outputs":[],"source":["BATCH_SIZE = 32\n","MAX_SEQ_LEN = 7\n","VOCAB_SIZE = 6000 "]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T14:58:30.094300Z","iopub.status.busy":"2024-08-08T14:58:30.093581Z","iopub.status.idle":"2024-08-08T14:58:30.127973Z","shell.execute_reply":"2024-08-08T14:58:30.127229Z","shell.execute_reply.started":"2024-08-08T14:58:30.094269Z"},"trusted":true},"outputs":[],"source":["DATASET_PATH = '/kaggle/working/poem_dataset.csv'\n","\n","df = pd.read_csv(DATASET_PATH, index_col=0)\n","df['content'] = df['content'].apply(lambda p: text_normalize(p))\n","corpus = df['content'].to_numpy()\n","\n","X = []\n","y = []\n","for idx, row in df.iterrows():\n","    lines = row['content'].split('\\n')\n","    lines = [line for line in lines if line != '']\n","    for idx in range(0, len(lines) - 1):\n","        input_sentence = lines[idx]\n","        output_sentence = lines[idx+1]\n","\n","        X.append(input_sentence)\n","        y.append(output_sentence)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T14:58:33.117549Z","iopub.status.busy":"2024-08-08T14:58:33.116694Z","iopub.status.idle":"2024-08-08T14:58:33.123143Z","shell.execute_reply":"2024-08-08T14:58:33.122212Z","shell.execute_reply.started":"2024-08-08T14:58:33.117515Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Input: <start> cái làm ta hạnh phúc <end> => <start> thực ra cũng chẳng nhiều <end>\n","Input: <start> thực ra cũng chẳng nhiều <end> => <start> chỉ cần có ai đó <end>\n","Input: <start> chỉ cần có ai đó <end> => <start> để ta thầm thương yêu <end>\n","Input: <start> để ta thầm thương yêu <end> => <start> rồi thêm chút công việc <end>\n","Input: <start> rồi thêm chút công việc <end> => <start> cho ta làm hàng ngày <end>\n","Input: <start> cho ta làm hàng ngày <end> => <start> cuối cùng chút mơ mộng <end>\n","Input: <start> cuối cùng chút mơ mộng <end> => <start> để đưa ta lên mây <end>\n","Input: <start> chiều vừa xốp trên tay <end> => <start> chợt nghe thoáng ong bay <end>\n","Input: <start> chợt nghe thoáng ong bay <end> => <start> có ai vừa chết nhỉ <end>\n","Input: <start> có ai vừa chết nhỉ <end> => <start> mây thắt tang trăng gầy <end>\n"]}],"source":["for idx in range(len(X))[:10]:\n","    print(f'Input: {X[idx]} => {y[idx]}')"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T14:58:35.343014Z","iopub.status.busy":"2024-08-08T14:58:35.342041Z","iopub.status.idle":"2024-08-08T14:58:35.359137Z","shell.execute_reply":"2024-08-08T14:58:35.358243Z","shell.execute_reply.started":"2024-08-08T14:58:35.342980Z"},"trusted":true},"outputs":[],"source":["tokenizer = Tokenizer(num_words=VOCAB_SIZE, filters='', oov_token=\"<OOV>\")\n","tokenizer.fit_on_texts(corpus)\n","\n","VOCAB_SIZE = len(tokenizer.word_index) + 1"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T14:58:38.950548Z","iopub.status.busy":"2024-08-08T14:58:38.949896Z","iopub.status.idle":"2024-08-08T14:58:38.994726Z","shell.execute_reply":"2024-08-08T14:58:38.993834Z","shell.execute_reply.started":"2024-08-08T14:58:38.950515Z"},"trusted":true},"outputs":[],"source":["def prepare_output_sequences(y_sequences):\n","    y_inputs = pad_sequences([y_seq[:-1] for y_seq in y_sequences], maxlen=MAX_SEQ_LEN, truncating='pre', padding='post')\n","    y_outputs = pad_sequences([y_seq[1:] for y_seq in y_sequences], maxlen=MAX_SEQ_LEN, truncating='pre', padding='post')\n","\n","    return y_inputs, y_outputs\n","\n","X_sequences = tokenizer.texts_to_sequences(X)\n","X_padded_sequences = pad_sequences(X_sequences, maxlen=MAX_SEQ_LEN, truncating='pre', padding='post')\n","\n","y_sequences = tokenizer.texts_to_sequences(y)\n","y_inputs, y_outputs = prepare_output_sequences(y_sequences)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T14:58:42.836550Z","iopub.status.busy":"2024-08-08T14:58:42.835935Z","iopub.status.idle":"2024-08-08T14:58:42.845290Z","shell.execute_reply":"2024-08-08T14:58:42.844345Z","shell.execute_reply.started":"2024-08-08T14:58:42.836518Z"},"trusted":true},"outputs":[],"source":["n_samples = len(X_padded_sequences)\n","train_len = int(n_samples * 0.7)\n","val_len = int(n_samples * 0.2)\n","test_len = n_samples - train_len - val_len\n","\n","# Shuffle \n","np.random.seed(1)\n","idxs = np.arange(n_samples)\n","idxs = np.random.permutation(idxs)\n","\n","X_padded_sequences = X_padded_sequences[idxs]\n","y_inputs = y_inputs[idxs]\n","y_outputs = y_outputs[idxs]\n","\n","# Split the data into train, validation, and test sets\n","X_train_seq, y_train_input, y_train_output = X_padded_sequences[:train_len], y_inputs[:train_len], y_outputs[:train_len]\n","X_val_seq, y_val_input, y_val_output = X_padded_sequences[train_len:train_len+val_len], y_inputs[train_len:train_len+val_len], y_outputs[train_len:train_len+val_len]\n","X_test_seq, y_test_input, y_test_output = X_padded_sequences[train_len+val_len:], y_inputs[train_len+val_len:], y_outputs[train_len+val_len:]"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T14:58:47.501726Z","iopub.status.busy":"2024-08-08T14:58:47.500941Z","iopub.status.idle":"2024-08-08T14:58:48.146737Z","shell.execute_reply":"2024-08-08T14:58:48.145886Z","shell.execute_reply.started":"2024-08-08T14:58:47.501691Z"},"trusted":true},"outputs":[],"source":["train_ds = tf.data.Dataset.from_tensor_slices(((X_train_seq, y_train_input), y_train_output)).batch(BATCH_SIZE)\n","val_ds = tf.data.Dataset.from_tensor_slices(((X_val_seq, y_val_input), y_val_output)).batch(BATCH_SIZE)\n","test_ds = tf.data.Dataset.from_tensor_slices(((X_test_seq, y_test_input), y_test_output)).batch(BATCH_SIZE)\n","\n","AUTOTUNE = tf.data.AUTOTUNE\n","\n","train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n","val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n","test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T14:58:51.519746Z","iopub.status.busy":"2024-08-08T14:58:51.518903Z","iopub.status.idle":"2024-08-08T14:58:51.529328Z","shell.execute_reply":"2024-08-08T14:58:51.528257Z","shell.execute_reply.started":"2024-08-08T14:58:51.519710Z"},"trusted":true},"outputs":[],"source":["# Build model\n","# Positional Encoding Layer\n","def positional_encoding(length, depth):\n","    depth = depth/2\n","\n","    positions = np.arange(length)[:, np.newaxis]     # (seq, 1)\n","    depths = np.arange(depth)[np.newaxis, :]/depth   # (1, depth)\n","\n","    angle_rates = 1 / (10000**depths)         # (1, depth)\n","    angle_rads = positions * angle_rates      # (pos, depth)\n","\n","    pos_encoding = np.concatenate(\n","        [np.sin(angle_rads), np.cos(angle_rads)],\n","        axis=-1) \n","\n","    return tf.cast(pos_encoding, dtype=tf.float32)\n","\n","class PositionalEmbedding(tf.keras.layers.Layer):\n","    def __init__(self, vocab_size, d_model):\n","        super().__init__()\n","        self.d_model = d_model\n","        self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero=True) \n","        self.pos_encoding = positional_encoding(length=2048, depth=d_model)\n","\n","    def compute_mask(self, *args, **kwargs):\n","        return self.embedding.compute_mask(*args, **kwargs)\n","\n","    def call(self, x):\n","        length = tf.shape(x)[1]\n","        x = self.embedding(x)\n","        # This factor sets the relative scale of the embedding and positonal_encoding.\n","        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n","        x = x + self.pos_encoding[tf.newaxis, :length, :]\n","        return x"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T14:58:55.294672Z","iopub.status.busy":"2024-08-08T14:58:55.294316Z","iopub.status.idle":"2024-08-08T14:58:55.300461Z","shell.execute_reply":"2024-08-08T14:58:55.299602Z","shell.execute_reply.started":"2024-08-08T14:58:55.294643Z"},"trusted":true},"outputs":[],"source":["# Self-attenttion layer\n","class BaseAttention(tf.keras.layers.Layer):\n","    def __init__(self, **kwargs):\n","        super().__init__()\n","        self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n","        self.layernorm = tf.keras.layers.LayerNormalization()\n","        self.add = tf.keras.layers.Add()"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T14:58:57.318077Z","iopub.status.busy":"2024-08-08T14:58:57.317696Z","iopub.status.idle":"2024-08-08T14:58:57.324065Z","shell.execute_reply":"2024-08-08T14:58:57.323140Z","shell.execute_reply.started":"2024-08-08T14:58:57.318045Z"},"trusted":true},"outputs":[],"source":["# Cross-attention layer\n","class CrossAttention(BaseAttention):\n","    def call(self, x, context):\n","        attn_output, attn_scores = self.mha(\n","            query=x,\n","            key=context,\n","            value=context,\n","            return_attention_scores=True)\n","\n","        # Cache the attention scores for plotting later.\n","        self.last_attn_scores = attn_scores\n","\n","        x = self.add([x, attn_output])\n","        x = self.layernorm(x)\n","\n","        return x"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T14:58:59.919993Z","iopub.status.busy":"2024-08-08T14:58:59.919622Z","iopub.status.idle":"2024-08-08T14:58:59.925455Z","shell.execute_reply":"2024-08-08T14:58:59.924551Z","shell.execute_reply.started":"2024-08-08T14:58:59.919961Z"},"trusted":true},"outputs":[],"source":["# Global self-attention layer\n","class GlobalSelfAttention(BaseAttention):\n","    def call(self, x):\n","        attn_output = self.mha(\n","            query=x,\n","            value=x,\n","            key=x)\n","        x = self.add([x, attn_output])\n","        x = self.layernorm(x)\n","        \n","        return x"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T14:59:02.583568Z","iopub.status.busy":"2024-08-08T14:59:02.582886Z","iopub.status.idle":"2024-08-08T14:59:02.588684Z","shell.execute_reply":"2024-08-08T14:59:02.587788Z","shell.execute_reply.started":"2024-08-08T14:59:02.583537Z"},"trusted":true},"outputs":[],"source":["# Causal self-attention layer\n","class CausalSelfAttention(BaseAttention):\n","    def call(self, x):\n","        attn_output = self.mha(\n","            query=x,\n","            value=x,\n","            key=x,\n","            use_causal_mask = True)\n","        x = self.add([x, attn_output])\n","        x = self.layernorm(x)\n","        \n","        return x"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T14:59:05.167650Z","iopub.status.busy":"2024-08-08T14:59:05.167274Z","iopub.status.idle":"2024-08-08T14:59:05.175133Z","shell.execute_reply":"2024-08-08T14:59:05.174105Z","shell.execute_reply.started":"2024-08-08T14:59:05.167621Z"},"trusted":true},"outputs":[],"source":["# Feed-forward network\n","class FeedForward(tf.keras.layers.Layer):\n","    def __init__(self, d_model, dff, dropout_rate=0.1):\n","        super().__init__()\n","        self.seq = tf.keras.Sequential([\n","        tf.keras.layers.Dense(dff, activation='relu'),\n","        tf.keras.layers.Dense(d_model),\n","        tf.keras.layers.Dropout(dropout_rate)\n","        ])\n","        self.add = tf.keras.layers.Add()\n","        self.layer_norm = tf.keras.layers.LayerNormalization()\n","\n","    def call(self, x):\n","        x = self.add([x, self.seq(x)])\n","        x = self.layer_norm(x) \n","        return x"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T14:59:09.988861Z","iopub.status.busy":"2024-08-08T14:59:09.988526Z","iopub.status.idle":"2024-08-08T14:59:09.995221Z","shell.execute_reply":"2024-08-08T14:59:09.994150Z","shell.execute_reply.started":"2024-08-08T14:59:09.988834Z"},"trusted":true},"outputs":[],"source":["# Encoder layer\n","class EncoderLayer(tf.keras.layers.Layer):\n","    def __init__(self,*, d_model, num_heads, dff, dropout_rate=0.1):\n","        super().__init__()\n","\n","        self.self_attention = GlobalSelfAttention(\n","            num_heads=num_heads,\n","            key_dim=d_model,\n","            dropout=dropout_rate)\n","\n","        self.ffn = FeedForward(d_model, dff)\n","\n","    def call(self, x):\n","        x = self.self_attention(x)\n","        x = self.ffn(x)\n","        return x"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T14:59:13.766596Z","iopub.status.busy":"2024-08-08T14:59:13.765961Z","iopub.status.idle":"2024-08-08T14:59:13.775227Z","shell.execute_reply":"2024-08-08T14:59:13.774158Z","shell.execute_reply.started":"2024-08-08T14:59:13.766561Z"},"trusted":true},"outputs":[],"source":["# Transformer encoder\n","class Encoder(tf.keras.layers.Layer):\n","    def __init__(self, *, num_layers, d_model, num_heads,\n","                dff, vocab_size, dropout_rate=0.1):\n","        super().__init__()\n","\n","        self.d_model = d_model\n","        self.num_layers = num_layers\n","\n","        self.pos_embedding = PositionalEmbedding(\n","            vocab_size=vocab_size, d_model=d_model)\n","\n","        self.enc_layers = [\n","            EncoderLayer(d_model=d_model,\n","                        num_heads=num_heads,\n","                        dff=dff,\n","                        dropout_rate=dropout_rate)\n","            for _ in range(num_layers)]\n","        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n","\n","    def call(self, x):\n","        # `x` is token-IDs shape: (batch, seq_len)\n","        x = self.pos_embedding(x)  # Shape `(batch_size, seq_len, d_model)`.\n","\n","        # Add dropout.\n","        x = self.dropout(x)\n","\n","        for i in range(self.num_layers):\n","            x = self.enc_layers[i](x)\n","\n","        return x  # Shape `(batch_size, seq_len, d_model)`."]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T14:59:16.830497Z","iopub.status.busy":"2024-08-08T14:59:16.829615Z","iopub.status.idle":"2024-08-08T14:59:16.837913Z","shell.execute_reply":"2024-08-08T14:59:16.836863Z","shell.execute_reply.started":"2024-08-08T14:59:16.830465Z"},"trusted":true},"outputs":[],"source":["# Decoder layer\n","class DecoderLayer(tf.keras.layers.Layer):\n","    def __init__(self,\n","                *,\n","                d_model,\n","                num_heads,\n","                dff,\n","                dropout_rate=0.1):\n","        super(DecoderLayer, self).__init__()\n","\n","        self.causal_self_attention = CausalSelfAttention(\n","            num_heads=num_heads,\n","            key_dim=d_model,\n","            dropout=dropout_rate)\n","\n","        self.cross_attention = CrossAttention(\n","            num_heads=num_heads,\n","            key_dim=d_model,\n","            dropout=dropout_rate)\n","\n","        self.ffn = FeedForward(d_model, dff)\n","\n","    def call(self, x, context):\n","        x = self.causal_self_attention(x=x)\n","        x = self.cross_attention(x=x, context=context)\n","\n","        # Cache the last attention scores for plotting later\n","        self.last_attn_scores = self.cross_attention.last_attn_scores\n","\n","        x = self.ffn(x)  # Shape `(batch_size, seq_len, d_model)`.\n","        return x"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T14:59:20.607571Z","iopub.status.busy":"2024-08-08T14:59:20.607217Z","iopub.status.idle":"2024-08-08T14:59:20.616387Z","shell.execute_reply":"2024-08-08T14:59:20.615441Z","shell.execute_reply.started":"2024-08-08T14:59:20.607541Z"},"trusted":true},"outputs":[],"source":["# Transformer Decoder\n","class Decoder(tf.keras.layers.Layer):\n","    def __init__(self, *, num_layers, d_model, num_heads, dff, vocab_size,\n","                dropout_rate=0.1):\n","        super(Decoder, self).__init__()\n","\n","        self.d_model = d_model\n","        self.num_layers = num_layers\n","\n","        self.pos_embedding = PositionalEmbedding(vocab_size=vocab_size,\n","                                                d_model=d_model)\n","        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n","        self.dec_layers = [\n","            DecoderLayer(d_model=d_model, num_heads=num_heads,\n","                        dff=dff, dropout_rate=dropout_rate)\n","            for _ in range(num_layers)]\n","\n","        self.last_attn_scores = None\n","\n","    def call(self, x, context):\n","        # `x` is token-IDs shape (batch, target_seq_len)\n","        x = self.pos_embedding(x)  # (batch_size, target_seq_len, d_model)\n","\n","        x = self.dropout(x)\n","\n","        for i in range(self.num_layers):\n","            x  = self.dec_layers[i](x, context)\n","\n","        self.last_attn_scores = self.dec_layers[-1].last_attn_scores\n","\n","        # The shape of x is (batch_size, target_seq_len, d_model).\n","        return x"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T14:59:23.640217Z","iopub.status.busy":"2024-08-08T14:59:23.639478Z","iopub.status.idle":"2024-08-08T14:59:23.648379Z","shell.execute_reply":"2024-08-08T14:59:23.647299Z","shell.execute_reply.started":"2024-08-08T14:59:23.640186Z"},"trusted":true},"outputs":[],"source":["# Transformer model\n","class Transformer(tf.keras.Model):\n","    def __init__(self, *, num_layers, d_model, num_heads, dff,\n","                vocab_size, dropout_rate=0.1):\n","        super().__init__()\n","        self.encoder = Encoder(num_layers=num_layers, d_model=d_model,\n","                            num_heads=num_heads, dff=dff,\n","                            vocab_size=vocab_size,\n","                            dropout_rate=dropout_rate)\n","\n","        self.decoder = Decoder(num_layers=num_layers, d_model=d_model,\n","                            num_heads=num_heads, dff=dff,\n","                            vocab_size=vocab_size,\n","                            dropout_rate=dropout_rate)\n","\n","        self.final_layer = tf.keras.layers.Dense(vocab_size)\n","\n","    def call(self, inputs):\n","        # To use a Keras model with `.fit` you must pass all your inputs in the\n","        # first argument.\n","        context, x  = inputs\n","\n","        context = self.encoder(context)  # (batch_size, context_len, d_model)\n","\n","        x = self.decoder(x, context)  # (batch_size, target_len, d_model)\n","\n","        # Final linear layer output.\n","        logits = self.final_layer(x)  # (batch_size, target_len, target_vocab_size)\n","\n","        try:\n","            # Drop the keras mask, so it doesn't scale the losses/metrics.\n","            # b/250038731\n","            del logits._keras_mask\n","        except AttributeError:\n","            pass\n","\n","        # Return the final output and the attention weights.\n","        return logits"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T14:59:27.286184Z","iopub.status.busy":"2024-08-08T14:59:27.285812Z","iopub.status.idle":"2024-08-08T14:59:27.290879Z","shell.execute_reply":"2024-08-08T14:59:27.289861Z","shell.execute_reply.started":"2024-08-08T14:59:27.286153Z"},"trusted":true},"outputs":[],"source":["N_LAYERS = 4\n","D_MODEL = 128\n","D_FF = 512\n","N_HEADS = 8\n","DROPOUT_RATE = 0.2"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T14:59:30.397911Z","iopub.status.busy":"2024-08-08T14:59:30.396866Z","iopub.status.idle":"2024-08-08T14:59:30.558119Z","shell.execute_reply":"2024-08-08T14:59:30.557351Z","shell.execute_reply.started":"2024-08-08T14:59:30.397867Z"},"trusted":true},"outputs":[],"source":["transformer = Transformer(\n","    num_layers=N_LAYERS,\n","    d_model=D_MODEL,\n","    num_heads=N_HEADS,\n","    dff=D_FF,\n","    vocab_size=VOCAB_SIZE,\n","    dropout_rate=DROPOUT_RATE\n",")"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T14:59:33.311369Z","iopub.status.busy":"2024-08-08T14:59:33.310519Z","iopub.status.idle":"2024-08-08T14:59:33.372352Z","shell.execute_reply":"2024-08-08T14:59:33.371382Z","shell.execute_reply.started":"2024-08-08T14:59:33.311325Z"},"trusted":true},"outputs":[],"source":["batches = train_ds.take(2)\n","for batch in batches:\n","    X_try, y_try = batch[0], batch[1]\n","    break"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T14:59:35.590473Z","iopub.status.busy":"2024-08-08T14:59:35.589975Z","iopub.status.idle":"2024-08-08T14:59:44.069611Z","shell.execute_reply":"2024-08-08T14:59:44.068649Z","shell.execute_reply.started":"2024-08-08T14:59:35.590421Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'query' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'key' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'value' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'global_self_attention' (of type GlobalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'sequential' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'feed_forward' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'encoder_layer' (of type EncoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'global_self_attention_1' (of type GlobalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'sequential_1' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'feed_forward_1' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'encoder_layer_1' (of type EncoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'global_self_attention_2' (of type GlobalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'sequential_2' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'feed_forward_2' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'encoder_layer_2' (of type EncoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'global_self_attention_3' (of type GlobalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'sequential_3' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'feed_forward_3' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'encoder_layer_3' (of type EncoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'causal_self_attention' (of type CausalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'cross_attention' (of type CrossAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'sequential_4' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'feed_forward_4' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'decoder_layer' (of type DecoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'causal_self_attention_1' (of type CausalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'cross_attention_1' (of type CrossAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'sequential_5' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'feed_forward_5' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'decoder_layer_1' (of type DecoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'causal_self_attention_2' (of type CausalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'cross_attention_2' (of type CrossAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'sequential_6' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'feed_forward_6' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'decoder_layer_2' (of type DecoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'causal_self_attention_3' (of type CausalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'cross_attention_3' (of type CrossAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'sequential_7' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'feed_forward_7' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'decoder_layer_3' (of type DecoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n"]},{"data":{"text/plain":["TensorShape([32, 7, 1471])"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["output = transformer(X_try)\n","output.shape"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T14:59:50.398093Z","iopub.status.busy":"2024-08-08T14:59:50.397444Z","iopub.status.idle":"2024-08-08T14:59:50.423423Z","shell.execute_reply":"2024-08-08T14:59:50.422533Z","shell.execute_reply.started":"2024-08-08T14:59:50.398061Z"},"trusted":true},"outputs":[{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"transformer\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ encoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Encoder</span>)               │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,827,136</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ decoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Decoder</span>)               │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,938,112</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1471</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">189,759</span> │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ encoder (\u001b[38;5;33mEncoder\u001b[0m)               │ ?                      │     \u001b[38;5;34m2,827,136\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ decoder (\u001b[38;5;33mDecoder\u001b[0m)               │ ?                      │     \u001b[38;5;34m4,938,112\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1471\u001b[0m)          │       \u001b[38;5;34m189,759\u001b[0m │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,955,007</span> (30.35 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,955,007\u001b[0m (30.35 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,955,007</span> (30.35 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,955,007\u001b[0m (30.35 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"}],"source":["transformer.summary()"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T15:00:25.294917Z","iopub.status.busy":"2024-08-08T15:00:25.294021Z","iopub.status.idle":"2024-08-08T15:00:25.301823Z","shell.execute_reply":"2024-08-08T15:00:25.300649Z","shell.execute_reply.started":"2024-08-08T15:00:25.294884Z"},"trusted":true},"outputs":[],"source":["# Config model\n","class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n","    def __init__(self, d_model, warmup_steps=4000):\n","        super().__init__()\n","\n","        self.d_model = d_model\n","        self.d_model = tf.cast(self.d_model, tf.float32)\n","\n","        self.warmup_steps = warmup_steps\n","\n","    def __call__(self, step):\n","        step = tf.cast(step, dtype=tf.float32)\n","        arg1 = tf.math.rsqrt(step)\n","        arg2 = step * (self.warmup_steps ** -1.5)\n","\n","        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T15:00:27.749359Z","iopub.status.busy":"2024-08-08T15:00:27.748871Z","iopub.status.idle":"2024-08-08T15:00:27.758254Z","shell.execute_reply":"2024-08-08T15:00:27.757454Z","shell.execute_reply.started":"2024-08-08T15:00:27.749326Z"},"trusted":true},"outputs":[],"source":["learning_rate = CustomSchedule(D_MODEL)\n","\n","optimizer = tf.keras.optimizers.Adam(\n","    learning_rate, \n","    beta_1=0.9, \n","    beta_2=0.98,\n","    epsilon=1e-9\n",")"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T15:00:30.534833Z","iopub.status.busy":"2024-08-08T15:00:30.533993Z","iopub.status.idle":"2024-08-08T15:00:30.546506Z","shell.execute_reply":"2024-08-08T15:00:30.545587Z","shell.execute_reply.started":"2024-08-08T15:00:30.534800Z"},"trusted":true},"outputs":[],"source":["def masked_loss(label, pred):\n","    mask = label != 0\n","    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n","        from_logits=True, reduction='none')\n","    loss = loss_object(label, pred)\n","\n","    mask = tf.cast(mask, dtype=loss.dtype)\n","    loss *= mask\n","\n","    loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n","\n","    return loss\n","\n","\n","def masked_accuracy(label, pred):\n","    pred = tf.argmax(pred, axis=2)\n","    label = tf.cast(label, pred.dtype)\n","    match = label == pred\n","\n","    mask = label != 0\n","\n","    match = match & mask\n","\n","    match = tf.cast(match, dtype=tf.float32)\n","    mask = tf.cast(mask, dtype=tf.float32)\n","    \n","    return tf.reduce_sum(match)/tf.reduce_sum(mask)\n","\n","def compute_perplexity(logits, targets):\n","    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n","        from_logits=True, reduction='none')\n","\n","    loss = loss_fn(targets, logits)\n","\n","    perplexity = np.exp(np.mean(loss))\n","\n","    return perplexity\n","\n","\n","def compute_bleu(predicted, targets):\n","    predicted_strings = []\n","    for seq in predicted:\n","        seq = np.argmax(seq, axis=1)\n","        string_seq = \" \".join([tokenizer.sequences_to_texts([[token]])[0] for token in seq if token != 0])\n","        predicted_strings.append(string_seq)\n","    target_strings = []\n","    for seq in targets:\n","        seq = seq.numpy().tolist()\n","        string_seq = \" \".join([tokenizer.sequences_to_texts([[token]])[0] for token in seq if token != 0])\n","        target_strings.append([string_seq])  \n","\n","    bleu_score = corpus_bleu(target_strings, predicted_strings)\n","\n","    return bleu_score"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T15:00:34.497855Z","iopub.status.busy":"2024-08-08T15:00:34.497496Z","iopub.status.idle":"2024-08-08T15:00:34.507778Z","shell.execute_reply":"2024-08-08T15:00:34.506900Z","shell.execute_reply.started":"2024-08-08T15:00:34.497829Z"},"trusted":true},"outputs":[],"source":["transformer.compile(\n","    loss=masked_loss,\n","    optimizer=optimizer,\n","    metrics=[masked_accuracy]\n",")"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T15:00:37.950896Z","iopub.status.busy":"2024-08-08T15:00:37.950080Z","iopub.status.idle":"2024-08-08T15:02:04.772442Z","shell.execute_reply":"2024-08-08T15:02:04.771480Z","shell.execute_reply.started":"2024-08-08T15:00:37.950866Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","\u001b[1m 7/23\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 7.3732 - masked_accuracy: 0.0000e+00"]},{"name":"stderr","output_type":"stream","text":["WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","I0000 00:00:1723129280.044553     117 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","W0000 00:00:1723129280.098815     117 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - loss: 7.3461 - masked_accuracy: 5.8225e-04 - val_loss: 7.1674 - val_masked_accuracy: 0.0256\n","Epoch 2/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 7.0726 - masked_accuracy: 0.1058 - val_loss: 6.8029 - val_masked_accuracy: 0.1667\n","Epoch 3/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 6.7503 - masked_accuracy: 0.1667 - val_loss: 6.6356 - val_masked_accuracy: 0.1667\n","Epoch 4/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6.6081 - masked_accuracy: 0.1667 - val_loss: 6.5612 - val_masked_accuracy: 0.1667\n","Epoch 5/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6.5262 - masked_accuracy: 0.1667 - val_loss: 6.4941 - val_masked_accuracy: 0.1667\n","Epoch 6/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 6.4417 - masked_accuracy: 0.1667 - val_loss: 6.4179 - val_masked_accuracy: 0.1667\n","Epoch 7/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 6.3481 - masked_accuracy: 0.1681 - val_loss: 6.3393 - val_masked_accuracy: 0.1734\n","Epoch 8/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 6.2508 - masked_accuracy: 0.1721 - val_loss: 6.2640 - val_masked_accuracy: 0.1756\n","Epoch 9/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 6.1501 - masked_accuracy: 0.1733 - val_loss: 6.1938 - val_masked_accuracy: 0.1771\n","Epoch 10/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 6.0400 - masked_accuracy: 0.1764 - val_loss: 6.1278 - val_masked_accuracy: 0.1778\n","Epoch 11/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5.9118 - masked_accuracy: 0.1784 - val_loss: 6.0641 - val_masked_accuracy: 0.1778\n","Epoch 12/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5.7590 - masked_accuracy: 0.1830 - val_loss: 6.0022 - val_masked_accuracy: 0.1830\n","Epoch 13/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5.5892 - masked_accuracy: 0.1940 - val_loss: 5.9478 - val_masked_accuracy: 0.1834\n","Epoch 14/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5.4051 - masked_accuracy: 0.2054 - val_loss: 5.8970 - val_masked_accuracy: 0.1882\n","Epoch 15/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5.2207 - masked_accuracy: 0.2221 - val_loss: 5.8490 - val_masked_accuracy: 0.1937\n","Epoch 16/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5.0559 - masked_accuracy: 0.2434 - val_loss: 5.8275 - val_masked_accuracy: 0.1864\n","Epoch 17/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.8885 - masked_accuracy: 0.2694 - val_loss: 5.7838 - val_masked_accuracy: 0.1974\n","Epoch 18/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.7218 - masked_accuracy: 0.3065 - val_loss: 5.7537 - val_masked_accuracy: 0.1971\n","Epoch 19/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4.5567 - masked_accuracy: 0.3490 - val_loss: 5.7243 - val_masked_accuracy: 0.1974\n","Epoch 20/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.3927 - masked_accuracy: 0.3824 - val_loss: 5.7016 - val_masked_accuracy: 0.1971\n","Epoch 21/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.2217 - masked_accuracy: 0.4342 - val_loss: 5.6963 - val_masked_accuracy: 0.1945\n","Epoch 22/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4.0737 - masked_accuracy: 0.4516 - val_loss: 5.7026 - val_masked_accuracy: 0.2023\n","Epoch 23/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3.9174 - masked_accuracy: 0.5121 - val_loss: 5.6998 - val_masked_accuracy: 0.2038\n","Epoch 24/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3.7402 - masked_accuracy: 0.5636 - val_loss: 5.6840 - val_masked_accuracy: 0.2134\n","Epoch 25/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3.5937 - masked_accuracy: 0.5837 - val_loss: 5.7049 - val_masked_accuracy: 0.2056\n","Epoch 26/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3.4592 - masked_accuracy: 0.6373 - val_loss: 5.7072 - val_masked_accuracy: 0.2096\n","Epoch 27/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3.2722 - masked_accuracy: 0.6476 - val_loss: 5.7219 - val_masked_accuracy: 0.2193\n","Epoch 28/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3.0923 - masked_accuracy: 0.7192 - val_loss: 5.6869 - val_masked_accuracy: 0.2179\n","Epoch 29/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2.9442 - masked_accuracy: 0.7331 - val_loss: 5.6826 - val_masked_accuracy: 0.2167\n","Epoch 30/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2.7682 - masked_accuracy: 0.7572 - val_loss: 5.6981 - val_masked_accuracy: 0.2267\n","Epoch 31/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.5496 - masked_accuracy: 0.8028 - val_loss: 5.7144 - val_masked_accuracy: 0.2241\n","Epoch 32/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2.3793 - masked_accuracy: 0.8316 - val_loss: 5.6974 - val_masked_accuracy: 0.2286\n","Epoch 33/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.2386 - masked_accuracy: 0.8493 - val_loss: 5.7163 - val_masked_accuracy: 0.2301\n","Epoch 34/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2.0722 - masked_accuracy: 0.8868 - val_loss: 5.7035 - val_masked_accuracy: 0.2301\n","Epoch 35/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.8972 - masked_accuracy: 0.8981 - val_loss: 5.7047 - val_masked_accuracy: 0.2245\n","Epoch 36/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.7174 - masked_accuracy: 0.9303 - val_loss: 5.7631 - val_masked_accuracy: 0.2293\n","Epoch 37/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.5622 - masked_accuracy: 0.9351 - val_loss: 5.8253 - val_masked_accuracy: 0.2286\n","Epoch 38/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.4080 - masked_accuracy: 0.9469 - val_loss: 5.8143 - val_masked_accuracy: 0.2348\n","Epoch 39/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.2807 - masked_accuracy: 0.9590 - val_loss: 5.7673 - val_masked_accuracy: 0.2382\n","Epoch 40/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.1244 - masked_accuracy: 0.9671 - val_loss: 5.7903 - val_masked_accuracy: 0.2316\n","Epoch 41/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.9893 - masked_accuracy: 0.9815 - val_loss: 5.8359 - val_masked_accuracy: 0.2367\n","Epoch 42/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.8670 - masked_accuracy: 0.9818 - val_loss: 5.8290 - val_masked_accuracy: 0.2396\n","Epoch 43/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.7402 - masked_accuracy: 0.9895 - val_loss: 5.8702 - val_masked_accuracy: 0.2441\n","Epoch 44/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.6389 - masked_accuracy: 0.9889 - val_loss: 5.9063 - val_masked_accuracy: 0.2308\n","Epoch 45/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5569 - masked_accuracy: 0.9907 - val_loss: 5.8938 - val_masked_accuracy: 0.2390\n","Epoch 46/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.4706 - masked_accuracy: 0.9918 - val_loss: 5.8987 - val_masked_accuracy: 0.2364\n","Epoch 47/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.4103 - masked_accuracy: 0.9909 - val_loss: 5.9284 - val_masked_accuracy: 0.2386\n","Epoch 48/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.3453 - masked_accuracy: 0.9917 - val_loss: 5.9636 - val_masked_accuracy: 0.2356\n","Epoch 49/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.2883 - masked_accuracy: 0.9921 - val_loss: 5.9826 - val_masked_accuracy: 0.2386\n","Epoch 50/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.2398 - masked_accuracy: 0.9922 - val_loss: 6.0108 - val_masked_accuracy: 0.2434\n"]}],"source":["# Training\n","history = transformer.fit(\n","    train_ds,\n","    epochs=50,\n","    validation_data=val_ds\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T15:02:09.967553Z","iopub.status.busy":"2024-08-08T15:02:09.967180Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 833ms/step - loss: 6.5006 - masked_accuracy: 0.1936\n"]}],"source":["test_evaluation = transformer.evaluate(test_ds)\n","\n","train_loss, train_acc = history.history['loss'], history.history['masked_accuracy'] # Đọc thông tin loss, acc trên tập train\n","val_loss, val_acc = history.history['val_loss'], history.history['val_masked_accuracy'] # Đọc thông tin loss, acc trên tập val\n","\n","plt.figure(figsize=(10, 10)) \n","\n","plt.subplot(2, 2, 1) \n","plt.xlabel('Epochs')  \n","plt.ylabel('Loss')  \n","plt.title('Training loss')  \n","plt.plot(train_loss, color='green') \n","\n","plt.subplot(2, 2, 2)  \n","plt.xlabel('Epochs')  \n","plt.ylabel('Accuracy')  \n","plt.title('Training accuracy') \n","plt.plot(train_acc, color='orange') \n","\n","plt.subplot(2, 2, 3)  \n","plt.xlabel('Epochs')  \n","plt.ylabel('Loss')  \n","plt.title('Validation loss')  \n","plt.plot(val_loss, color='green')  \n","\n","plt.subplot(2, 2, 4)  \n","plt.xlabel('Epochs')  \n","plt.ylabel('Accuracy')  \n","plt.title('Validation accuracy')  \n","plt.plot(val_acc, color='orange') \n","\n","plt.show() "]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T15:02:17.116609Z","iopub.status.busy":"2024-08-08T15:02:17.116238Z","iopub.status.idle":"2024-08-08T15:02:17.128502Z","shell.execute_reply":"2024-08-08T15:02:17.127505Z","shell.execute_reply.started":"2024-08-08T15:02:17.116581Z"},"trusted":true},"outputs":[],"source":["# Generate poem\n","def generate_text(\n","    generator_model, \n","    tokenizer,\n","    input_string\n","    ):\n","    \n","    encoder_input_string = text_normalize(input_string) \n","    encoder_input_sequence = tokenizer.texts_to_sequences([encoder_input_string])\n","    encoder_input_padded_sequence = pad_sequences(encoder_input_sequence, maxlen=MAX_SEQ_LEN, truncating='pre', padding='post')[0]\n","    encoder_input_padded_sequence = np.expand_dims(encoder_input_padded_sequence, axis=0)\n","\n","    decoder_input_string = '<start>'\n","    decoder_input_sequence = tokenizer.texts_to_sequences([decoder_input_string])\n","    decoder_input_padded_sequence = pad_sequences(decoder_input_sequence, maxlen=MAX_SEQ_LEN, truncating='pre', padding='post')[0]\n","    start = decoder_input_padded_sequence[0][tf.newaxis]\n","    end = decoder_input_padded_sequence[1][tf.newaxis]\n","    decoder_input_padded_sequence = np.expand_dims(decoder_input_padded_sequence, axis=0)\n","\n","    output_array = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)\n","    output_array = output_array.write(0, start)\n","\n","    for i in tf.range(MAX_SEQ_LEN):\n","        output = tf.transpose(output_array.stack())\n","        predictions = generator_model((encoder_input_padded_sequence, output), training=False)\n","\n","        # Select the last token from the `seq_len` dimension.\n","        predictions = predictions[:, -1:, :]  # Shape `(batch_size, 1, vocab_size)`.\n","\n","        predicted_id = tf.argmax(predictions, axis=-1)\n","\n","        # Concatenate the `predicted_id` to the output which is given to the\n","        # decoder as its input.\n","        output_array = output_array.write(i+1, predicted_id[0])\n","\n","        if predicted_id == end:\n","            break\n","\n","    output = tf.transpose(output_array.stack())\n","    output_tokens = output.numpy()\n","    # The output shape is `(1, tokens)`.\n","    text = tokenizer.sequences_to_texts(output_tokens)[0]  # Shape: `()`.\n","\n","\n","    # `tf.function` prevents us from using the attention_weights that were\n","    # calculated on the last iteration of the loop.\n","    # So, recalculate them outside the loop.\n","    generator_model([decoder_input_padded_sequence, output[:, :-1]], training=False)\n","    attention_weights = generator_model.decoder.last_attn_scores\n","\n","    return text, output_tokens, attention_weights"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T15:03:11.000228Z","iopub.status.busy":"2024-08-08T15:03:10.999500Z","iopub.status.idle":"2024-08-08T15:03:23.856984Z","shell.execute_reply":"2024-08-08T15:03:23.856111Z","shell.execute_reply.started":"2024-08-08T15:03:11.000197Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["trăng không che nổi gió\n"," đất trời bừng giác ngộ  \n"," đất hiến dâng tuổi trẻ  \n"," trời buông thả tuổi già  \n"," ôi mùa xuân bất tận  \n"," anh về từ trận một  \n"," anh về từ cơn mưa  \n"," từ những ngày đã qua  \n"," rồi anh thì có anh  \n"]}],"source":["n_sentences = 7\n","results = ['trăng không che nổi gió']\n","for idx in range(n_sentences + 1):\n","    input_str = results[idx]\n","    text, output_tokens, attention_weights = generate_text(\n","        transformer, \n","        tokenizer,\n","        input_str\n","    )\n","    results.append(text.replace('<start>', '').replace('<end>', ''))\n","\n","print('\\n'.join(results))"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30747,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
